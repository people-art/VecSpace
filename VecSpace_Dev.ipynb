{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11zZvcp9C4-QKT640MhB0xVmH8jlADPFd",
      "authorship_tag": "ABX9TyMvpmQPLW5qVtfmetAR3HsG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/people-art/VecSpace/blob/main/VecSpace_Dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 演示使用VecSpace（向量数据空间）构建智能体“记忆”\n",
        "\n"
      ],
      "metadata": {
        "id": "l9IDjB5dUNWX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbsCGQjZTBXF"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-colab"
      ],
      "metadata": {
        "id": "vcR_1W1DXbQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vecspace"
      ],
      "metadata": {
        "id": "jAUgUJqwUyZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import vecspace\n",
        "import openai\n",
        "from google.colab import drive\n",
        "\n",
        "OPENAI_API_KEY = \"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\"\n",
        "\n",
        "client = vecspace.Client()\n",
        "openai.api_key = OPENAI_API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp6FLpxkTVaB",
        "outputId": "936c27bd-627f-4c37-d522-9c07a7174978"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:vecspace:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def complete(prompt):\n",
        "    res = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return res['choices'][0]['message']['content'].strip()\n",
        "\n",
        "def get_ada_embedding(text):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    return openai.Embedding.create(input=text, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n",
        "\n",
        "\n",
        "# Define a function to process a batch of texts\n",
        "def process_batch(text_batch, collection, start_index):\n",
        "    batch_embeddings = [get_ada_embedding(text) for text in text_batch]\n",
        "    batch_metadatas = [{\"text\": text} for text in text_batch]\n",
        "    batch_ids = [\"test-openai-\" + str(i) for i in range(start_index, start_index+len(text_batch))]\n",
        "    \n",
        "    collection.add(embeddings=batch_embeddings, metadatas=batch_metadatas, ids=batch_ids)\n",
        "\n",
        "# Define a function for threads to execute\n",
        "def worker(queue):\n",
        "    while not queue.empty():\n",
        "        text_batch = queue.get()\n",
        "        process_batch(text_batch, collection, queue)\n",
        "        queue.task_done()\n",
        "\n"
      ],
      "metadata": {
        "id": "nS3QPfVsTrxq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 读文本\n",
        "\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "#with open('/content/drive/MyDrive/ai-avatar/xiyouji.txt', 'r', encoding='utf-8') as f:\n",
        "    content = f.read()\n",
        "\n",
        "texts = \"\"\"\n",
        "  As interest rates have risen, venture funding has subsided over the past year. With the era of “free money” seemingly over, it’s always in your best interest to see where the “smart money” is investing.\n",
        "  The evolution of data management has seen a shift from relational (SQL) databases, which are designed for structured data and rely on fixed schemas, to NoSQL databases, which offer more flexibility in handling unstructured or semi-structured data. Vector databases represent the next step in this evolution, providing an optimized solution for managing and querying high-dimensional vector data (i.e. vector embeddings), which is often generated by machine learning and AI applications.\n",
        "  A high-dimensional space is a mathematical concept that represents a space with many dimensions, where each dimension is a separate axis or feature of the data. In practical terms, a high-dimensional space is simply a way to describe data that has many features or attributes.\n",
        "  Let’s say you have a collection of words, and you want to represent them in a way that a computer can understand and process. One way to do this is by using something called “embeddings.\n",
        "  Think of embeddings as a way to turn words into points on a map. Each word gets its own spot on the map, and similar words are close to each other, while different words are far apart. This “map” is like a grid, but with more than just two directions (up/down and left/right).\n",
        "  The “directions” on this map are called dimensions. Each dimension is like a different characteristic or feature of a word. For example, one dimension might represent how “happy” a word is, while another might represent whether it’s an animal or not. The more dimensions we have, the more characteristics we can capture about each word.\n",
        "  A “vector” is like a set of instructions that tells you how to get to a word’s location on the map. It contains numbers for each dimension that help you find the word’s exact spot. When we talk about “vector embeddings,” we’re talking about these sets of numbers that represent the location of words on our multi-dimensional map.\n",
        "  So, in simple terms, embeddings are a way to turn words into points on a map with many directions (dimensions), and vectors are the sets of numbers that help us find the location of each word on that map.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#print(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbdbaXMGTw2l",
        "outputId": "463ae74e-e391-4877-8ada-38dd156e5ca6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建vecspace\n",
        "\n",
        "from vecspace.utils import embedding_functions\n",
        "from queue import Queue\n",
        "import threading\n",
        "\n",
        "import uuid\n",
        "VECSPACE_NAME = \"vecspace.name-\" + str(uuid.uuid4())\n",
        "\n",
        "# Create the VecSpace collection\n",
        "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_key=OPENAI_API_KEY,\n",
        "    model_name=\"text-embedding-ada-002\"\n",
        ")\n",
        "collection = client.create_collection(VECSPACE_NAME, embedding_function=openai_ef)\n",
        "\n",
        "# Set batch size and number of threads\n",
        "batch_size = 1000\n",
        "num_threads = 10\n",
        "\n",
        "# Split the texts into batches\n",
        "text_batches = [texts[i:i+batch_size] for i in range(0, len(texts), batch_size)]\n",
        "\n",
        "\n",
        "# Create a ThreadPoolExecutor and submit tasks\n",
        "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "    futures = []\n",
        "    for i, text_batch in enumerate(text_batches):\n",
        "        futures.append(executor.submit(process_batch, text_batch, collection, i * batch_size))\n",
        "\n",
        "    # Wait for all tasks to complete\n",
        "    for future in futures:\n",
        "        future.result()\n",
        "\n",
        "print(\"All texts have been processed and added to the collection.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmIo2swLZfoM",
        "outputId": "d93e6045-6752-4924-b448-2a2b2c6f6ca7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All texts have been processed and added to the collection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_text = \"embeddings maps words into points.\"\n",
        "\n",
        "results = collection.query(\n",
        "    query_embeddings=get_ada_embedding(query_text), \n",
        "    n_results=5\n",
        "    )\n",
        "\n",
        "import json\n",
        "print(json.dumps(results, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFdsyV8CUB9v",
        "outputId": "8914ba2d-9eb0-4fb4-cbb8-c345b95dd617"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"ids\": [\n",
            "    [\n",
            "      \"test-openai-1113\",\n",
            "      \"test-openai-1319\",\n",
            "      \"test-openai-1374\",\n",
            "      \"test-openai-1449\",\n",
            "      \"test-openai-1482\"\n",
            "    ]\n",
            "  ],\n",
            "  \"embeddings\": null,\n",
            "  \"documents\": [\n",
            "    [\n",
            "      null,\n",
            "      null,\n",
            "      null,\n",
            "      null,\n",
            "      null\n",
            "    ]\n",
            "  ],\n",
            "  \"metadatas\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"d\"\n",
            "      },\n",
            "      {\n",
            "        \"text\": \"d\"\n",
            "      },\n",
            "      {\n",
            "        \"text\": \"d\"\n",
            "      },\n",
            "      {\n",
            "        \"text\": \"d\"\n",
            "      },\n",
            "      {\n",
            "        \"text\": \"d\"\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"distances\": [\n",
            "    [\n",
            "      0.49438947439193726,\n",
            "      0.49438947439193726,\n",
            "      0.49438947439193726,\n",
            "      0.49438947439193726,\n",
            "      0.49438947439193726\n",
            "    ]\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "rguoyHdhY_r3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JvdkoUOjUGqj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}